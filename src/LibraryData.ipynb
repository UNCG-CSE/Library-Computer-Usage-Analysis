{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Timestamps to Minutes Per Hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following attempts to take non-uniform timestamps and do the following:\n",
    "* resample those timestamps into minutes\n",
    "* forward-fill the states\n",
    "* resample the minutes into hours, summing the minutes\n",
    "\n",
    "The function `.resample()` changed in pandas 0.18.1, so this was a learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(\"This should be '0.20.1':\")\n",
    "print(\"pandas:         \" + str(pd.__version__))\n",
    "print(\"This should be '1.12.1':\")\n",
    "print(\"numpy:          \" + str(np.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing the data from the Library data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useData = pd.read_csv(r'../data/170830_StateData.csv',parse_dates=[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying the status of the columns. 'datastamp' should be a datetime64 field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "useData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing functionality with a single computer. Working with iterating across the numpy array later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "computerDataName = 'CRR005'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "computerTimeArray = useData[useData.machineName == computerDataName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "computerTimeArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This turns the 'in-use' value into true, and all of the others into false. Since this analysis is based upon when a machine is not being used (as opposed to when it is offline/available/restarted) all other states are irrelevant.\n",
    "\n",
    "Will need to investigate copy/view on this error. May need to do this as a dataframe with `.concat()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "computerTimeArray.loc[:,'state'] = pd.Series(computerTimeArray.state == 'in-use')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location data is irrelevant for a machine at this point. Also, location can be derived from machine name, machine location is (at this point) not that precise.\n",
    "\n",
    "Pandas was giving a duplicate error due to the three non- 'in-use' states occurring simultaneously. Dropping unused columns for data duplication (machinename and location), and dropping timestamp duplications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "computerTimeArray = computerTimeArray.loc[:,'state':'datestamp'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "computerTimeArray = computerTimeArray.set_index('datestamp').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "computerTimeArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes the above data and resamples it into minute increments. Value for the specific minute is put into place, while 'NaN' values will take on the previous non-NaN data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "computerTimeArrayMin = computerTimeArray.resample('T').ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "computerTimeArrayPerHour = computerTimeArrayMin.resample('H').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "computerTimeArrayPerHour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative method of computing per-machine utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the intervals during which each computer was in use.\n",
    "# @df must be a pandas DataFrame with columns ['machineName',\n",
    "# 'location', 'state', 'datestamp'].\n",
    "# Returns a dictionary keyed by 'machineName' with values\n",
    "# of (timestamp, timerange) corresponding to sessions of machine\n",
    "# usage.\n",
    "def toUsageIntervals(df):\n",
    "    # Bin records by @machineName.\n",
    "    binned = {}\n",
    "    names = df['machineName'].unique()\n",
    "    for name in names:\n",
    "        matching = df[df['machineName'] == name]\n",
    "        binned[name] = matching.loc[:,'state':'datestamp'].sort_values(by='datestamp')\n",
    "\n",
    "    # Compute date ranges of usage for each machine.\n",
    "    for (name, frame) in binned.items():\n",
    "        # Mark which records correspond to 'in-use'.\n",
    "        inUse = list(frame['state'] == 'in-use')\n",
    "        # Each consecutive True/False corresponds to a period of activity.\n",
    "        # Compute a DateRange from each consecutive True/False pair.\n",
    "        indexedInUse = list(zip(range(0,len(inUse),1), inUse))\n",
    "        transitions = [(frame.iloc[x[0]].loc['datestamp'], frame.iloc[y[0]].loc['datestamp']) for (x, y) in zip(indexedInUse[:-1], indexedInUse[1:]) if x[1]==True and y[1]==False]\n",
    "        dateRanges = [(x, y-x) for (x, y) in transitions]\n",
    "        binned[name] = dateRanges\n",
    "    return binned\n",
    "\n",
    "from pandas.tseries.offsets import *\n",
    "import functools\n",
    "import itertools\n",
    "\n",
    "# Convert date ranges into hourly usage data.\n",
    "def usageIntervalsToPercentUtilization(binned, period='h'):\n",
    "    def dateRangeToPeriodUtilization(begin, length):\n",
    "        # Round the starting time down to the nearest period.\n",
    "        start = begin.floor(period)\n",
    "        if ((begin + length).floor(period) == start):\n",
    "            # If we don't cross a period boundary, just return the amount of time\n",
    "            # spent 'in-use' for this period.\n",
    "            return [(start, pd.Timedelta(length))]\n",
    "        else:\n",
    "            # Otherwise, we need to break the session down by period, according to wall-time.\n",
    "            # We already have the beginning of this interval.  Round up the end time to the\n",
    "            # nearest period to get the end-point of the interval.\n",
    "            end = (begin + length).ceil(period)\n",
    "            # Now create a list of timestamps corresponding to periods on the clock for this\n",
    "            # session.\n",
    "            # One would think 'closed=None' means don't include the first or last value\n",
    "            # in the interval.  This doesn't seem to be the case though, so manually remove\n",
    "            # those values.  Otherwise, we end up with two copies of the start period, and\n",
    "            # two copies of the end period.\n",
    "            periods = pd.date_range(start, end, freq=period, closed=None)[1:-1]\n",
    "            # Compute the amount of time spent 'in-use' in the first hour-long interval.\n",
    "            first = pd.Timedelta('1' + period) - (begin - start)\n",
    "            # Similarly for the last hour-long interval.\n",
    "            last = pd.Timedelta('1' + period) - (end - (begin + length))\n",
    "            # Create a list of (timestamp,timerange) pairs giving the total amount of time\n",
    "            # spent 'in-use' for each period-long interval.\n",
    "            return list(zip([start] + list(periods), [first] + ([pd.Timedelta('1' + period)] * (len(periods) - 1)) + [last]))\n",
    "\n",
    "    def concat(lists):\n",
    "        return [] if len(lists)==0 else functools.reduce(lambda x, y: x + y, lists)\n",
    "\n",
    "    def dateRangeToDataFrame(dateRanges):\n",
    "        # Convert each date range into a list of (timestamp,timerange) where each timestamp\n",
    "        # corresponds to a period within the timerange.\n",
    "        next_ = concat(list(map(lambda x: dateRangeToPeriodUtilization(x[0], x[1]), dateRanges)))\n",
    "        # Group and sum times by period to remove duplicate periods, which would happen if\n",
    "        # we have multiple timeranges within a period, e.g. if we have two entries\n",
    "        # ('2017-08-31 09:02:00', '+00:05:00') and ('2017-08-31 09:10:00', '+00:13:00').\n",
    "        dic = {}\n",
    "        for (x, y) in next_:\n",
    "            if x not in dic:\n",
    "                dic[x] = y\n",
    "            else:\n",
    "                dic[x] += y\n",
    "        # Group the results into a pair of ([timestamp],[timerange]) with unique timestamps.\n",
    "        z = list(zip(*dic.items()))\n",
    "        # return a value of type [(timestamp, double)]\n",
    "        return [(x, y / pd.Timedelta(1, unit=period)) for (x, y) in dic.items()]\n",
    "\n",
    "    # utilization has type [(name, [(timestamp, double)])]\n",
    "    utilization = [(x, dateRangeToDataFrame(y)) for (x, y) in binned.items()]\n",
    "    # get the unique list of timestamps in the data set\n",
    "    all_timestamps = map(lambda x: map(lambda y: y[0], x[1]), utilization)\n",
    "    unique_timestamps = functools.reduce(lambda x, y: set(list(x) + list(y)), all_timestamps, set([]))\n",
    "    sorted_timestamps = sorted(unique_timestamps)\n",
    "    # sorted_timestamps has type [timestamp]\n",
    "    # add a bogus (timestamp, 0.0) value for each unique timestamp to the data for each computer\n",
    "    bogus = [(x, 0.0) for x in sorted_timestamps]\n",
    "    bogus_utilization = [(x, y + bogus) for (x, y) in utilization]\n",
    "    # now, per computer, group data by timestamp.  each group will contain at most one valid (i.e. measured)\n",
    "    # data point, and one bogus data point.\n",
    "    groups = [(x, itertools.groupby(sorted(y, key=lambda z: z[0]), key=lambda z: z[0])) for (x, y) in bogus_utilization]\n",
    "    # groups has type [(name, [(timestamp, [(timestamp, double)])])]\n",
    "    # for each computer, select the entry in each group representing the higher utilization.  the only\n",
    "    # options within each group are actual reported utilization, or zero.  so if the machine was used,\n",
    "    # the number we're looking for is the only non-zero value.\n",
    "    full_utilization = [(x, [sorted(w, key=lambda v: v[1], reverse=True)[0][1] for (_, w) in group]) for (x, group) in groups]\n",
    "    return pd.DataFrame(dict(full_utilization), index=sorted_timestamps)\n",
    "\n",
    "utilization = usageIntervalsToPercentUtilization(toUsageIntervals(useData))\n",
    "utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crr005 = utilization['CRR005']\n",
    "crr005.where(lambda x: x>0).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "computerTimeArrayPerHour.where(lambda x: x>0).dropna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
